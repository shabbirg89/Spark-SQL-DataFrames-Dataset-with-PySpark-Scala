{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://LAPTOP-MKM81J0P:4040\n",
       "SparkContext available as 'sc' (version = 3.0.0, master = local[*], app id = local-1599499211351)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import scala.util.Random\r\n",
       "rdd: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[1] at map at <console>:26\r\n",
       "DF: org.apache.spark.sql.DataFrame = [key: int, value: int]\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Generate Spark Dataframe from a RDD in Scala\n",
    "import scala.util.Random\n",
    "val rdd = spark.sparkContext.parallelize(1 to 10).map(x => (x,Random.nextInt(100)* x))\n",
    "val DF = rdd.toDF(\"key\",\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: integer (nullable = false)\n",
      " |-- value: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Check for the structure\n",
    "DF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|key|value|\n",
      "+---+-----+\n",
      "|  1|   10|\n",
      "|  2|   94|\n",
      "|  3|   66|\n",
      "|  4|  268|\n",
      "|  5|  105|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//View it as a Spark DataFrame\n",
    "DF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\r\n",
       "import org.apache.spark.sql.types._\r\n",
       "peopleRDD: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = ParallelCollectionRDD[8] at parallelize at <console>:27\r\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(id,LongType,true), StructField(name,StringType,true), StructField(age,LongType,true))\r\n",
       "peopleDF: org.apache.spark.sql.DataFrame = [id: bigint, name: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.types._\n",
    "val peopleRDD = spark.sparkContext.parallelize(Array(Row(1L, \"Shabbir\", 30L),Row(2L, \"Vivek\", 25L)))\n",
    "val schema = StructType(Array(\n",
    "StructField(\"id\", LongType, true),\n",
    "StructField(\"name\", StringType, true),\n",
    "StructField(\"age\", LongType, true)\n",
    "))\n",
    "val peopleDF = spark.createDataFrame(peopleRDD, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  1|Shabbir| 30|\n",
      "|  2|  Vivek| 25|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peopleDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|num|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df1: Unit = ()\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Spark Dataframe using the range function\n",
    "val df1 = spark.range(5).toDF(\"num\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movies: Seq[(String, String, Long)] = List((Damon, Matt,The Bourne Ultimatum,2007), (Damon, Matt,Good Will Hunting,1997))\r\n",
       "moviesDF: org.apache.spark.sql.DataFrame = [actor: string, title: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Convert Sequence key-values to spark DataFrame\n",
    "val movies = Seq((\"Damon, Matt\", \"The Bourne Ultimatum\", 2007L),(\"Damon, Matt\", \"Good Will Hunting\", 1997L))\n",
    "val moviesDF = movies.toDF(\"actor\", \"title\", \"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- actor: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----+\n",
      "|      actor|               title|year|\n",
      "+-----------+--------------------+----+\n",
      "|Damon, Matt|The Bourne Ultimatum|2007|\n",
      "|Damon, Matt|   Good Will Hunting|1997|\n",
      "+-----------+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 10 more fields]\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Initialize Dataframe reader and to csv local system\n",
    "val df = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\")\n",
    ".csv(\"C:/Users/sgove/OneDrive/Desktop/all.csv\")\n",
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: Long = 1893059\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res9: Array[String] = Array(SYMBOL, SERIES, OPEN, HIGH, LOW, CLOSE, LAST, PREVCLOSE, TOTTRDQTY, TOTTRDVAL, TIMESTAMP, _c11)\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res10: Array[(String, String)] = Array((SYMBOL,StringType), (SERIES,StringType), (OPEN,DoubleType), (HIGH,DoubleType), (LOW,DoubleType), (CLOSE,DoubleType), (LAST,DoubleType), (PREVCLOSE,DoubleType), (TOTTRDQTY,IntegerType), (TOTTRDVAL,DoubleType), (TIMESTAMP,StringType), (_c11,IntegerType))\r\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+\n",
      "|  OPEN|   HIGH|  CLOSE|    LOW|\n",
      "+------+-------+-------+-------+\n",
      "| 37.75|  37.75|  37.45|  36.35|\n",
      "| 43.75|   45.3|   44.9|  43.75|\n",
      "|3374.0|3439.95| 3397.5| 3338.0|\n",
      "| 281.8| 294.45|  289.2|  279.8|\n",
      "| 127.0|  132.0|  131.3| 126.55|\n",
      "|  50.0|   50.0|  49.25|   49.0|\n",
      "| 58.45|  58.45|  56.65|   56.6|\n",
      "| 620.0| 645.95|  643.3|  617.0|\n",
      "| 796.8|  796.8|  785.2| 777.35|\n",
      "|1379.0| 1379.0| 1353.2|1335.05|\n",
      "|129.55|  130.8|  130.0| 128.35|\n",
      "| 367.0|  374.0|  370.0|  335.6|\n",
      "|  15.0|   16.0|  15.95|   15.0|\n",
      "|816.45|  844.7| 824.85|  812.4|\n",
      "|  14.4|  15.25|  15.05|   14.2|\n",
      "|1070.0| 1098.0|1091.85|1069.95|\n",
      "|  43.2|   44.9|   44.5|   42.0|\n",
      "| 228.0|  228.0|  224.5|  223.1|\n",
      "| 58.75|   62.7|  58.35|  58.35|\n",
      "| 666.0|  668.2|  661.0|  652.3|\n",
      "+------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Apply SQL like functions on spark dataframe with functional programming\n",
    "df.select(\"OPEN\",\"HIGH\",\"CLOSE\",\"LOW\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+---------------+-----------+----+\n",
      "|    SYMBOL|SERIES|   OPEN|   HIGH|    LOW|  CLOSE|   LAST|PREVCLOSE|TOTTRDQTY|      TOTTRDVAL|  TIMESTAMP|_c11|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+---------------+-----------+----+\n",
      "|   3MINDIA|    EQ| 3374.0|3439.95| 3338.0| 3397.5| 3400.0|   3364.7|      871|     2941547.35|01-APR-2011|null|\n",
      "|ASIANPAINT|    EQ|2568.95|2568.95| 2511.0|2520.55| 2515.3|   2525.8|    57384|  1.450865968E8|01-APR-2011|null|\n",
      "|   AVENTIS|    EQ| 2011.0| 2018.0|1976.15|1993.55| 1983.0|  2011.95|      569|      1138432.5|01-APR-2011|null|\n",
      "|  AXISGOLD|    EQ| 2075.0|2086.15| 2053.7| 2072.9| 2070.0|   2066.0|      476|       982519.7|01-APR-2011|null|\n",
      "|      BHEL|    EQ| 2077.4| 2134.7| 2062.0| 2127.7| 2124.0|  2062.65|   810279|1.71175017195E9|01-APR-2011|null|\n",
      "|  BOSCHLTD|    EQ|6501.05| 6800.0|6501.05|6659.15| 6674.0|   6708.5|     3139|  2.104645035E7|01-APR-2011|null|\n",
      "|       CMC|    EQ|2092.75| 2160.0| 2079.0| 2084.5| 2081.0|   2081.5|     4514|     9523674.85|01-APR-2011|null|\n",
      "|    CRISIL|    EQ| 6201.0| 6348.6| 6201.0|6284.65| 6275.0|   6313.1|      170|     1067886.25|01-APR-2011|null|\n",
      "|     GLAXO|    EQ| 2050.0| 2098.4|2025.15| 2090.9| 2094.4|  2062.95|     9255|   1.91502562E7|01-APR-2011|null|\n",
      "|  GOLDBEES|    EQ|2024.85| 2032.0| 2018.0| 2029.4| 2030.0|   2024.3|    22668|  4.598561285E7|01-APR-2011|null|\n",
      "| GOLDSHARE|    EQ| 2020.0| 2034.9|2015.15| 2032.1| 2034.7|  2012.25|     1268|     2571877.25|01-APR-2011|null|\n",
      "|    GRASIM|    EQ| 2484.0| 2548.0| 2469.9| 2530.9| 2527.5|   2456.9|   143564| 3.6267353095E8|01-APR-2011|null|\n",
      "|   GSKCONS|    EQ| 2250.0| 2250.0| 2182.0|2222.75| 2222.0|  2246.15|     1015|      2253679.8|01-APR-2011|null|\n",
      "|  HDFCBANK|    EQ| 2353.0| 2365.0| 2323.0|2333.75|2339.25|  2345.85|   436929|1.02014359875E9|01-APR-2011|null|\n",
      "|HDFCMFGETF|    EQ| 2071.0|2082.75| 2066.4|2080.25| 2074.0|  2066.45|      743|      1541873.1|01-APR-2011|null|\n",
      "|    HONAUT|    EQ| 2176.0| 2280.0|2048.35|2271.65| 2275.0|   2246.0|      307|      691264.75|01-APR-2011|null|\n",
      "|INFOSYSTCH|    EQ| 3235.1|3256.25| 3208.0|3218.15| 3219.1|   3241.3|   698536|2.25294791805E9|01-APR-2011|null|\n",
      "|    IPGETF|    EQ|2056.45| 2080.0|2056.45| 2080.0| 2080.0|  2069.55|       94|      194986.45|01-APR-2011|null|\n",
      "| KOTAKGOLD|    EQ| 2018.1| 2031.0| 2018.1|2027.55| 2026.0|  2020.95|     1294|      2622992.1|01-APR-2011|null|\n",
      "| LAXMIMACH|    EQ| 2273.9| 2305.0| 2222.0|2240.25|2238.05|  2232.95|     5131|  1.154153085E7|01-APR-2011|null|\n",
      "+----------+------+-------+-------+-------+-------+-------+---------+---------+---------------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"HIGH > 2000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+------+-------+-------+-------+---------+---------+--------------+-----------+----+\n",
      "|    SYMBOL|SERIES|  OPEN|  HIGH|    LOW|  CLOSE|   LAST|PREVCLOSE|TOTTRDQTY|     TOTTRDVAL|  TIMESTAMP|_c11|\n",
      "+----------+------+------+------+-------+-------+-------+---------+---------+--------------+-----------+----+\n",
      "| 20MICRONS|    EQ| 37.75| 37.75|  36.35|  37.45|   37.3|    37.15|    38638|     1420968.1|01-APR-2011|null|\n",
      "|3IINFOTECH|    EQ| 43.75|  45.3|  43.75|   44.9|   44.8|    43.85|  1239690| 5.531120435E7|01-APR-2011|null|\n",
      "|    A2ZMES|    EQ| 281.8|294.45|  279.8|  289.2|  287.2|    281.3|   140643|  4.02640755E7|01-APR-2011|null|\n",
      "|AARTIDRUGS|    EQ| 127.0| 132.0| 126.55|  131.3|  130.6|    127.6|     2972|      384468.2|01-APR-2011|null|\n",
      "|  AARTIIND|    EQ|  50.0|  50.0|   49.0|  49.25|  49.35|    49.05|    24056|    1188195.85|01-APR-2011|null|\n",
      "| AARVEEDEN|    EQ| 58.45| 58.45|   56.6|  56.65|   56.6|    56.55|      123|        7000.1|01-APR-2011|null|\n",
      "|      ABAN|    EQ| 620.0|645.95|  617.0|  643.3|  644.0|   616.25|  1192421|7.5745251715E8|01-APR-2011|null|\n",
      "|       ABB|    EQ| 796.8| 796.8| 777.35|  785.2|  780.2|    796.8|    58038| 4.562089595E7|01-APR-2011|null|\n",
      "|ABBOTINDIA|    EQ|1379.0|1379.0|1335.05| 1353.2| 1355.0|  1343.05|      587|      793494.8|01-APR-2011|null|\n",
      "|     ABCIL|    EQ|129.55| 130.8| 128.35|  130.0|  130.0|    129.7|     1941|      251299.4|01-APR-2011|null|\n",
      "|   ABGSHIP|    EQ| 367.0| 374.0|  335.6|  370.0|  370.0|   363.75|   307293| 1.134908749E8|01-APR-2011|null|\n",
      "|  ABHISHEK|    EQ|  15.0|  16.0|   15.0|  15.95|   16.0|     15.2|     6360|      100264.3|01-APR-2011|null|\n",
      "|ABIRLANUVO|    EQ|816.45| 844.7|  812.4| 824.85|  824.9|   814.35|    70865|  5.86104648E7|01-APR-2011|null|\n",
      "|ABSHEKINDS|    EQ|  14.4| 15.25|   14.2|  15.05|   15.2|     14.2|   159188|     2365626.1|01-APR-2011|null|\n",
      "|       ACC|    EQ|1070.0|1098.0|1069.95|1091.85|1091.15|  1074.55|   240346| 2.598602339E8|01-APR-2011|null|\n",
      "|       ACE|    EQ|  43.2|  44.9|   42.0|   44.5|   44.5|     43.1|   142292|     6273701.1|01-APR-2011|null|\n",
      "|   ACKRUTI|    EQ| 228.0| 228.0|  223.1|  224.5|  225.5|    226.4|    23053|     5187103.8|01-APR-2011|null|\n",
      "| ACROPETAL|    EQ| 58.75|  62.7|  58.35|  58.35|  58.35|     61.4|  2507573| 1.513034327E8|01-APR-2011|null|\n",
      "|  ADANIENT|    EQ| 666.0| 668.2|  652.3|  661.0|  665.0|   666.55|   210396|1.3885739135E8|01-APR-2011|null|\n",
      "|ADANIPOWER|    EQ| 112.5| 117.0|  112.5| 115.65|  115.9|   112.75|   887519|  1.02540268E8|01-APR-2011|null|\n",
      "+----------+------+------+------+-------+-------+-------+---------+---------+--------------+-----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"HIGH < 2000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|              OPEN|              HIGH|\n",
      "+-------+------------------+------------------+\n",
      "|  count|           1893059|           1893059|\n",
      "|   mean| 361.2689533078383| 366.7326563885202|\n",
      "| stddev|1747.4329870382217|1763.9932112529843|\n",
      "|    min|              0.05|              0.05|\n",
      "|    max|          116480.0|          116490.0|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"OPEN\",\"HIGH\").describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "// register movies as global temporary view called movies_g\n",
    "df.createOrReplaceTempView(\"stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+-------+-------+-------+------+---------+---------+---------------+-----------+-----+\n",
      "|   SYMBOL|SERIES|  OPEN|   HIGH|    LOW|  CLOSE|  LAST|PREVCLOSE|TOTTRDQTY|      TOTTRDVAL|  TIMESTAMP| _c11|\n",
      "+---------+------+------+-------+-------+-------+------+---------+---------+---------------+-----------+-----+\n",
      "|GEOMETRIC|    EQ| 62.35|   64.5|   61.4|  63.25| 63.25|     61.3|    82246|     5179345.65|01-APR-2011| null|\n",
      "|      TCS|    EQ|1185.0|1198.75|1172.55|1180.15|1181.9|   1183.9|   899812|1.06351115885E9|01-APR-2011| null|\n",
      "|GEOMETRIC|    EQ| 100.7|  105.5|   99.1|  103.5|102.55|    100.2|   124482|   1.27532668E7|01-APR-2013| 2690|\n",
      "|      TCS|    EQ|1565.0| 1573.7|1551.25|1556.85|1552.1|  1575.75|   484406|  7.564599597E8|01-APR-2013|19638|\n",
      "|GEOMETRIC|    EQ| 116.0|  121.0|  116.0|  120.0| 120.2|   115.55|   644060|     7.701543E7|01-APR-2014| 6430|\n",
      "+---------+------+------+-------+-------+-------+------+---------+---------+---------------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Use Proper SQL queries on Spark DataSet & DataFrames\n",
    "spark.sql(\"select * from stocks where SYMBOL IN ('TCS','GEOMETRIC')\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|PEARSON_CORR_CLOSE|\n",
      "+------------------+\n",
      "|0.9997560995948557|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Check for Pearson Correlation\n",
    "spark.sql(\"SELECT CORR(CLOSE,OPEN) AS PEARSON_CORR_CLOSE FROM stocks\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a: org.apache.spark.sql.DataFrame = [SYMBOL: string, SERIES: string ... 10 more fields]\r\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Save a Spark DataFrame as a CSV file on your System\n",
    "val a = spark.sql(\"select * from stocks where SYMBOL IN ('TCS','GEOMETRIC')\")\n",
    "a.write.format(\"csv\").option(\"sep\", \",\").save(\"C:/Users/sgove/OneDrive/Desktop/DataFrametocsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
